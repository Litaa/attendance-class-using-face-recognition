{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class Attendance using Face Recognition (Haar Cascade and LBPH Algorithm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Internal Training - Dyah Nurlita S</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"assets/Attendance System.png\" width=\"1000\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Introduction</h2><br>\n",
    "Nowadays in the rapid growth technology, various systems are created to help human activities. And the system that commonly used is authentication system. Generally authentication system created using face detection and face recognition. Face detection is the objective of finding the faces (location and size) in an image and extract them, whilst face recognition is finding characteristics which best describe the image which already extracted from face detection.<br>\n",
    "How face recognition works :<br>\n",
    "1. Capture a picture of your face from a photo or video. <br>\n",
    "2. Facial recognition reads the geometry of your face, the distance between your eyes and the distance from forehead to chin.<br>\n",
    "3. Got the facial signature in mathematical formula and compared in database<br>\n",
    "4. A determination is made by comparing your faceprint with existing database.<br>\n",
    "Who uses Facial Recognition?<br>\n",
    "1. Social media : instagram (face filter), facebook (tag people in photo)<br>\n",
    "2. Mobile phone : security system (unlock phone)<br>\n",
    "3. Public places (airports, train station, market, etc) : CCTV<br>\n",
    "4. Classroom : class attendance <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Face Detection</h2><br>\n",
    "Face detection is the first and essential step in face recognition. It is used to detect face in real time and tracking of person or object. There are several method in face detection, these methods divided into four categories. These categories are as follows :<br>\n",
    "<img src=\"assets/facedetection.JPG\" width=\"400\"/><br>\n",
    "<b>1. Knowledge based :</b> This method is depends on the set of rules, and it is based on human knowledge to detect the faces.<br>\n",
    "<b>2. Feature based:</b> This method is defined by extracting some feature on the face.<br>\n",
    "<b>3. Template matching :</b> The main idea of this method is detect the faces based on correlation between template and input image.<br>\n",
    "<b>4. Appearance based :</b> This method depends on a set of delegate training face images to find out face models. In general appearance-based method rely on techniques from statistical analysis and machine learning to find the relevant characteristics of face images<br>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Haar Cascade</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Haar Cascade</b> is one of machine learning algorithm used to identify object in an image or video. Concept from Haar Cascade was proposed by Paul Viola and Michael Jones in their paper \"Rapid Object Detection using a Boosted Cascade of Simple Feature\". This algorithm has four main stages :<br>\n",
    "<h3>1. Haar Feature Selection</h3><br>\n",
    "In this stage the algorithm takes the image and convert it into 24x24 window. Each window have pixel by pixel and contains Haar features which is then extracted into numerical values. There are three formations of Haar features. The first edge feature, second line feature, and the last the four rectangle feature.<br>\n",
    "<img src=\"assets/haarFeature.JPG\" width=\"300\" /><br>\n",
    "Each feature results in a single value which is calculated by subtracting the sum of pixels under a bright rectangle from the sum of pixels under the dark rectangle. Formula as a follows :<br>\n",
    "<div style=\"text-align:center\">Feature = $\\sum$(feature in black area) - $\\sum$(feature in white area)</div><br>\n",
    "<h3>2. Integral Images</h3><br>\n",
    "Rectangle feature can be determined rapidly by implement Integral images. Generally integral images comprises of small units\n",
    "representation of a given image. Integral images can be used for calculate Haar feature by convert pixel input image into integral image and sum of all pixels inside a rectangle with only uses four values efficient. Given ilustration below :<br>\n",
    "<img src=\"assets/integralin.JPG\" width=\"500\" /><br>\n",
    "This image above represent converted value from matrix input image into matrix integral image. Matrix integral image have dark area and bright area, from the value around them we can calculate four value efficient to generate whether those rectangle have a features or not. <br>\n",
    "<img src=\"assets/cleardark.JPG\" width=\"500\" /><br>\n",
    "Four efficient value from integral image can be breakdown into the image below: <br>\n",
    "<img src=\"assets/integral2.JPG\" width=\"300\" /><br>\n",
    "Area in rectangle A calculated with formula as follows :<br>\n",
    "<div style=\"text-align:center\">$$A = L_4 - (L_2+L_3) + L_1$$</div><br>\n",
    "So, from our ilustration, we have value in bright area of $L_1$=2, $L_2$=12, $L_3$=25, and $L_4$=61, whlist in dark area $L_1$=12, $L_2$=23, $L_3$=61, $L_4$=177. Using the formula given above bright area have a value of 49 and the dark area have a value of 105. By subtract those two value we get a new single value feature from the rectangle.\n",
    "<h3>3. Adaptive Boosting</h3><br>\n",
    "The main idea from adaptive boosting is remove redundant features and choose only relevant features. AdaBoost is used to get the best features among all the features. These features called weak classifier. Adaboost will constructs a strong classifier as a linear combination of weighted simple weak classifiers. Boosting provides the ability to train a highly accurate classifier by taking a weighted average of the decisions made by the weak learners.\n",
    "<img src=\"assets/adaboost.JPG\" width=\"400\" /><br>\n",
    "<h3>4. Cascade Classifier</h3><br>\n",
    "The cascade classifier contains of a collection of stages.Each stage is trained using a Adaptive Boosting. Each stage of the classifier labels defined by sliding window as either positive or negative. Positive indicates that an object was found and negative indicates no objects were found. If the label is negative, the classification of this region is complete, and the detector slides the window to the next location. If the label is positive, the classifier passes the region to the next stage. The stages are designed to reject negative samples as fast as possible. The assumption from the window is : <br>\n",
    "* True Positive when a positive sample is correctly classified.<br>\n",
    "* False Positive when a negative sample is mistakenly classified as positive.<br>\n",
    "* False Negative when a positive sample is mistakenly classified as negative.<br>\n",
    "<img src=\"assets/cascade.JPG\" width=\"600\" /><br>\n",
    "\n",
    "Rough representation of the features:<br>\n",
    "<img src=\"assets/blockhaar.JPG\" width=\"200\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T10:35:05.521629Z",
     "start_time": "2020-06-24T10:35:04.551207Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\litaimut\\anaconda3\\lib\\site-packages\\IPython\\core\\display.py:701: UserWarning: Consider using IPython.display.IFrame instead\n",
      "  warnings.warn(\"Consider using IPython.display.IFrame instead\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe width=\"504\" height=\"480\" src=\"https://www.youtube.com/embed/hPCTwxF0qf4\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('<iframe width=\"504\" height=\"480\" src=\"https://www.youtube.com/embed/hPCTwxF0qf4\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Dive Deeper</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T10:35:05.532156Z",
     "start_time": "2020-06-24T10:35:05.525629Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Handoyo'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "name = (\"Ajeng\",\"Sitta\",\"Tomy\",\"Tiara\",\"Wulan\",\"David\",\"Fafil\",\"Arga\",\"Joe\",\"Tanesya\",\"Nabilah\",\"Husain\",\"Ina\",\"Iqbal\",\"Handoyo\")\n",
    "random.choice(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Face Recognition using LBPH Algorithm</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LBPH (Local Binary Pattern Histogram) is face recognition algorithm which labels the pixels of an image by thresholding the neighborhood of each pixel and considers the result as a binary number. Generally LBPH using 3x3 neighborhood of each pixel with the center value.<br>\n",
    "Steps in LBPH Algorithm : <br>\n",
    "<h3>1. Parameters</h3><br>\n",
    "<b>a. Neighbors :</b>pixel which surrounding the center value.<br>\n",
    "<b>b. Radius :</b>the distance between the center point pixel and the neighboring pixel<br>\n",
    "<b>c. Grid X :</b>the number of cells in the horizontal<br>\n",
    "<b>d. Grid Y :</b>the number of cells in the vertical<br><br>\n",
    "\n",
    "<h3>2. Training the Algorithm</h3><br>\n",
    "Create a dataset with the facial images of the people we want to recognize. Set an ID for each unit image. <br><br>\n",
    "\n",
    "<h3>3. Applying the LBP operation</h3><br>\n",
    "The first step in applying LBP operation is find the binary number in each number from central value, and then convert the binary value into decimal value to get the single value. Ilustration from the process can be defined as follows :<br>\n",
    "<img src=\"lbph.JPG\" width=\"500\" /><br>\n",
    "Formula from the above calculation is :<br>\n",
    "$$LBP(x_c,y_c) = \\sum_{n=0}^{n-1} s(i_n - i_c)2^n$$<br>\n",
    "$$\n",
    "s(x) = \\left\\{\n",
    "    \\begin{array}\\\\\n",
    "        1, & \\mbox{if } \\ x \\geq 0 \\\\\n",
    "        0, & \\mbox{if } \\ x < 0 \\\\\n",
    "    \\end{array}\n",
    "\\right.\n",
    "$$<br>\n",
    "\n",
    "Where $i_n$ is neighborhood pixel and $i_c$ is central pixel.<br>\n",
    "Steps in applying LBP operation :<br>\n",
    "1. From a grayscale image, we have a window size of 3x3 matrix pixel <br>\n",
    "2. 3x3 matrix containing each pixel around 0~255.<br>\n",
    "3. Take the central value from the matrix and uses as threshold. <br>\n",
    "4. Set binary value in each neighbor using the given formula (3)<br>\n",
    "5. Now the matrix containing only a binary number. And then concanate the binary value in clockwise direction.<br>\n",
    "6. Convert binary value into decimal value.<br>\n",
    "7. Set the decimal value as new central value of the matrix. Now, the image  represents better the characteristics of the original image.<br><br>\n",
    "\n",
    "<h3>4. Extract the Histogram</h3><br>\n",
    "The image devided into multiple grid of X and Y. Each grid represent the histogram which contain 256 position (0-255). To create the bigger histogram that represents the characteristics of the original image, we need to concanate histogram in each grid. The ilustration as a follows:<br> \n",
    "<img src=\"assets/histogram.JPG\" width=\"600\" /><br><br>\n",
    "\n",
    "<h3>5. Perform Face Recognition</h3><br>\n",
    "The last step is performing face recognition using the dataset that already trained. Each image form the training dataset represent by unique histogram, when there is an input image the algorithm will trained the image and compare with training dataset then return the image with the closest histogram. The closest histogram can be define by calculate the distance between histogram. Distance between histrogram calculated using Euclidean Distance, which given formula as follows :<br>\n",
    "$$D = \\sqrt{\\sum_{i=1}^{n}(hist1_i - hist2_i)^2}$$<br>\n",
    "The algorithm will return the calculated distance, which can be used as a confidence measurement. Lower confidence value are better because it means the distance between the two histograms is closer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Play With the Code!</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>System Limitation:</h3><br>\n",
    "1. Training data collected from several photo's of product team.<br>\n",
    "2. Only single person images are being fed to classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Install open cv library</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T10:35:05.829701Z",
     "start_time": "2020-06-24T10:35:05.535138Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# !pip install opencv-python\n",
    "# !pip install opencv-contrib-python --user\n",
    "# !pip install opencv-contrib-python --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Import packages</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-06-24T10:35:05.000Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Cretate face detection function</h4><br>\n",
    "Load the haar cascade xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-06-24T10:35:05.147Z"
    }
   },
   "outputs": [],
   "source": [
    "kernel_sharpening = np.array([[-1,-1,-1], \n",
    "                              [-1, 9,-1],\n",
    "                              [-1,-1,-1]])\n",
    " \n",
    "def faceDetection(test_img):\n",
    "    #Remove noise\n",
    "    gray_img=cv2.cvtColor(test_img,cv2.COLOR_BGR2GRAY)\n",
    "    gray_img = cv2.GaussianBlur(gray_img, (5, 5), 0)\n",
    "    \n",
    "    #Image segmentation step\n",
    "    edges = cv2.Canny(gray_img, 20, 60)\n",
    "    contours, _ = cv2.findContours(edges, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cv2.drawContours(edges, contours, -1, 255, 2)\n",
    "    inv_edges = cv2.bitwise_not(edges)\n",
    "    retval, img, msk, rect = cv2.floodFill(inv_edges, None, (0, 0), 0)\n",
    "    mask = cv2.bitwise_or(edges, inv_edges)\n",
    "    result = np.zeros(test_img.shape, dtype='uint8')\n",
    "    result[mask > 0, :] = test_img[mask > 0, :]\n",
    "\n",
    "    #Image sharpening\n",
    "    gray_img=cv2.cvtColor(result,cv2.COLOR_BGR2GRAY)\n",
    "    sharpened = cv2.filter2D(gray_img, -1, kernel_sharpening)\n",
    "    \n",
    "    face_haar_cascade=cv2.CascadeClassifier('HaarCascade/haarcascade_frontalface_default.xml')\n",
    "    faces=face_haar_cascade.detectMultiScale(sharpened,scaleFactor=1.32,minNeighbors=5)\n",
    "\n",
    "    return faces,sharpened"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Get the directory from dataset training images</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-06-24T10:35:05.173Z"
    }
   },
   "outputs": [],
   "source": [
    "def labels_for_training_data(directory):\n",
    "    faces=[]\n",
    "    faceID=[]\n",
    "\n",
    "    for path,subdirnames,filenames in os.walk(directory):\n",
    "        for filename in filenames:\n",
    "            if filename.startswith(\".\"):\n",
    "                print(\"Skipping system file\")\n",
    "                continue\n",
    "\n",
    "            id=os.path.basename(path)\n",
    "            img_path=os.path.join(path,filename)\n",
    "            print(\"img_path:\",img_path)\n",
    "            print(\"id:\",id)\n",
    "            test_img=cv2.imread(img_path)\n",
    "            if test_img is None:\n",
    "                print(\"Image not loaded properly\")\n",
    "                continue\n",
    "            faces_rect,gray_img=faceDetection(test_img)\n",
    "            if len(faces_rect)!=1:\n",
    "                continue\n",
    "            (x,y,w,h)=faces_rect[0]\n",
    "            roi_gray=gray_img[y:y+w,x:x+h]\n",
    "            faces.append(roi_gray)\n",
    "            faceID.append(int(id))\n",
    "    return faces,faceID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Train the image using LBPH Algorithm</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-06-24T10:35:05.217Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_classifier(faces,faceID):\n",
    "    face_recognizer=cv2.face.LBPHFaceRecognizer_create()\n",
    "    face_recognizer.train(faces,np.array(faceID))\n",
    "    return face_recognizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Draw rectangle as image detection</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-06-24T10:35:05.385Z"
    }
   },
   "outputs": [],
   "source": [
    "def draw_rect(test_img,face):\n",
    "    (x,y,w,h)=face\n",
    "    cv2.rectangle(test_img,(x,y),(x+w,y+h),(255,0,0),thickness=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Put the text based on the return ID</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-06-24T10:35:05.413Z"
    }
   },
   "outputs": [],
   "source": [
    "def put_text(test_img,text,x,y):\n",
    "    cv2.putText(test_img,text,(x,y),cv2.FONT_HERSHEY_DUPLEX,2,(255,0,0),4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-06-24T10:35:05.463Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# faces,faceID= labels_for_training_data('trainingImages')\n",
    "# face_recognizer= train_classifier(faces,faceID)\n",
    "# face_recognizer.write('trainingData.yml')\n",
    "\n",
    "face_recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "face_recognizer.read('trainingData.yml')\n",
    "\n",
    "\n",
    "name = {0 : \"Lita\",1 : \"Ajeng\", 2 : \"Joe\", 3:\"Fafilia\", 4:\"Sitta\", 5:\"Wulan\", 6:\"Ina\", 7:\"Tomy\", 8:\"Nabilah\", 9:\"Tanesya\"}\n",
    "\n",
    "cap=cv2.VideoCapture(0)\n",
    "\n",
    "col_names = ['Id', 'Name', 'Date', 'Time']\n",
    "attendance = pd.DataFrame(columns=col_names)\n",
    "\n",
    "while True:\n",
    "    ret,test_img=cap.read()\n",
    "    faces_detected,gray_img=faceDetection(test_img)\n",
    "\n",
    "\n",
    "    for face in faces_detected:\n",
    "        (x,y,w,h)=face\n",
    "        roi_gray=gray_img[y:y+w, x:x+h]\n",
    "        id_,confidence=face_recognizer.predict(roi_gray)\n",
    "        print(\"confidence:\",confidence)\n",
    "        print(\"id:\",id_)\n",
    "        draw_rect(test_img,face)\n",
    "        predicted_name=name[id_]\n",
    "        if confidence < 50:\n",
    "            ts = time.time()\n",
    "            date = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d')\n",
    "            timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')\n",
    "            attendance.loc[len(attendance)] = [id_, predicted_name, date, timeStamp]\n",
    "            put_text(test_img,predicted_name,x,y)\n",
    "        else:\n",
    "            id_ = 'Unknown'\n",
    "            name_ = str(id_)\n",
    "            put_text(test_img,name_,x,y)  \n",
    "    attendance = attendance.drop_duplicates(subset=['Id'], keep='first')\n",
    " \n",
    "    resized_img = cv2.resize(test_img, (1000, 700))\n",
    "    cv2.imshow('face recognition',resized_img)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "ts = time.time()\n",
    "date = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d')\n",
    "timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')\n",
    "Hour, Minute, Second = timeStamp.split(\":\")\n",
    "fileName = \"Attendance\"+os.sep+\"Attendance_\"+date+\"_\"+Hour+\"-\"+Minute+\"-\"+Second+\".csv\"\n",
    "attendance.to_csv(fileName, index=False)\n",
    "cap.release()\n",
    "cv2.destroyAllWindows\n",
    "\n",
    "print(\"Attendance Successfull\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Conclusion:</h2><br>\n",
    "Based on explanation above, we can conclude that :<br>\n",
    "1. We can implement Haar Cascade classifier xml template which provided by opencv to build facial detection. <br>\n",
    "2. LBPH is facial recognition algorithm which offer less computational method. <br>\n",
    "3. This attendance system performance's depend on video quality (camera quality, light, angle, and no obstacle). <br> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>LBB</h3><br>\n",
    "<h4>Option 1:</h4><br>\n",
    "Create image recognition using photos of your face as a test image. <br>\n",
    "What you need to do :<br>\n",
    "1. Create folder training data which contains existing photo's of product team (include your photo)<br>\n",
    "2. Create folder test data that saves only one photo of your face (used as test data)<br>\n",
    "3. Train your own training dataset using the code given<br>\n",
    "4. Modify the code to read test image data<br>\n",
    "5. Predict your test data, so it can recognize that it is your face<br>\n",
    "6. Take a screenshoot of your recognized image<br>\n",
    "<br>\n",
    "Example :<br>\n",
    "<img src=\"assets/lita.JPG\" width=\"300\" /><br>\n",
    "\n",
    "<h4>Option 2:</h4><br>\n",
    "Create attendance class system :<br>\n",
    "What you need to do:<br>\n",
    "1. Create folder training data which contains existing photo's of product team (include your photo)<br>\n",
    "2. Train your own training dataset using the code given<br>\n",
    "3. Create csv file that indicate attendance sucessfull  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Group</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-06-24T10:35:05.677Z"
    }
   },
   "outputs": [],
   "source": [
    "name = (\"Ajeng\",\"Sitta\",\"Tomy\",\"Tiara\",\"Wulan\",\"David\",\"Fafil\",\"Arga\",\"Joe\",\"Tanesya\",\"Nabilah\",\"Husain\",\"Ina\",\"Iqbal\",\"Handoyo\")\n",
    "random.sample(name,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. \n",
    "2. \n",
    "3. \n",
    "4. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
